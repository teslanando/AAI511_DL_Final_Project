{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pretty_midi\n",
    "from music21 import converter, chord\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout, Conv1D, MaxPooling1D, Flatten, BatchNormalization\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Collection | Pre-Processing | Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the dataset folder\n",
    "MIDI_FOLDER = \"./dataset\" \n",
    "CSV_FOLDER = \"./features_csv\"\n",
    "\n",
    "# Ensure the CSV folder exists\n",
    "os.makedirs(CSV_FOLDER, exist_ok=True)\n",
    "\n",
    "def extract_features(midi_path):\n",
    "    try:\n",
    "        midi_data = pretty_midi.PrettyMIDI(midi_path)\n",
    "        features = {}\n",
    "\n",
    "        # Extract global features like tempo and number of instruments\n",
    "        features['tempo'] = np.mean(midi_data.get_tempo_changes()[1])\n",
    "        features['num_instruments'] = len(midi_data.instruments)\n",
    "\n",
    "        # Extract note-level features for each instrument\n",
    "        notes = []\n",
    "        for instrument in midi_data.instruments:\n",
    "            for note in instrument.notes:\n",
    "                notes.append((note.pitch, note.start, note.end, note.velocity))\n",
    "\n",
    "        # Convert notes to a DataFrame to facilitate further analysis\n",
    "        if notes:\n",
    "            df_notes = pd.DataFrame(notes, columns=['Pitch', 'Start', 'End', 'Velocity'])\n",
    "            features['avg_pitch'] = df_notes['Pitch'].mean()\n",
    "            features['std_pitch'] = df_notes['Pitch'].std()\n",
    "            features['avg_velocity'] = df_notes['Velocity'].mean()\n",
    "            features['std_velocity'] = df_notes['Velocity'].std()\n",
    "\n",
    "        # Analyze chords using music21\n",
    "        score = converter.parse(midi_path)\n",
    "        chords = [ch for ch in score.chordify().recurse() if isinstance(ch, chord.Chord)]\n",
    "        pitches = [p for ch in chords for p in ch.pitches]\n",
    "        features['num_chords'] = len(chords)\n",
    "        features['unique_pitches'] = len(set(pitches))\n",
    "\n",
    "        return features\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {midi_path}: {e}\")\n",
    "        return {}\n",
    "\n",
    "def process_files():\n",
    "    csv_path = os.path.join(CSV_FOLDER, 'features.csv')\n",
    "    composers = ['Bach', 'Beethoven', 'Chopin', 'Mozart']\n",
    "    all_features = []\n",
    "\n",
    "    for composer in composers:\n",
    "        composer_path = os.path.join(MIDI_FOLDER, composer)\n",
    "        midi_files = [f for f in os.listdir(composer_path) if f.endswith('.mid')]\n",
    "\n",
    "        for filename in tqdm(midi_files, desc=f\"Processing {composer} files\"):\n",
    "            midi_path = os.path.join(composer_path, filename)\n",
    "            features = extract_features(midi_path)\n",
    "            if features:\n",
    "                features['filename'] = filename\n",
    "                features['composer'] = composer\n",
    "                all_features.append(features)\n",
    "\n",
    "    # Save all features to a CSV file\n",
    "    df = pd.DataFrame(all_features)\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    print(\"Features saved to:\", csv_path)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    process_files()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(input_shape, num_classes):\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling1D(pool_size=2))\n",
    "    model.add(LSTM(128, return_sequences=True))\n",
    "    model.add(LSTM(128))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dense(num_classes, activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the features from CSV\n",
    "df = pd.read_csv('./features_csv/features.csv')\n",
    "\n",
    "# Assuming 'composer' is the target variable\n",
    "X = df.drop(['composer', 'filename'], axis=1).values\n",
    "y = pd.get_dummies(df['composer']).values\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reshape input to be [samples, time steps, features]\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "# Build the model\n",
    "model = build_model((1, X_train.shape[2]), y_train.shape[1])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=64, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict classes\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_true_classes, y_pred_classes, target_names=df['composer'].unique()))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
    "plt.figure(figsize=(10, 7))\n",
    "sns.heatmap(cm, annot=True, fmt='g', xticklabels=df['composer'].unique(), yticklabels=df['composer'].unique())\n",
    "plt.title('Confusion Matrix')\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create model, required for KerasClassifier\n",
    "def create_model(optimizer='adam'):\n",
    "    return build_model((1, X_train.shape[2]), y_train.shape[1])\n",
    "\n",
    "# Wrap Keras model so it can be used by scikit-learn\n",
    "model = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "\n",
    "# Define the grid search parameters\n",
    "optimizer = ['SGD', 'RMSprop', 'Adam']\n",
    "batch_size = [32, 64, 128]\n",
    "epochs = [20, 50, 100]\n",
    "param_grid = dict(optimizer=optimizer, batch_size=batch_size, epochs=epochs)\n",
    "\n",
    "# Create Grid Search\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, cv=3)\n",
    "grid_result = grid.fit(X_train, y_train)\n",
    "\n",
    "# Print best results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
